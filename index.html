<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yan Bai</title>
  
  <meta name="author" content="Yan Bai">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="image/pku_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yan Bai（白燕）</name>
              </p>
              <p> I am a Ph.D student at the 
                <a href="http://idm.pku.edu.cn/en/">National Engineering Research Center of Visual Technology (NELVT)</a>,
                <a href="https://cs.pku.edu.cn/English/Home.htm">School of Computer Science</a>,
                <a href="https://english.pku.edu.cn/">Peking University</a>, supervised by Prof. <a href="https://scholar.google.com/citations?user=hsXZOgIAAAAJ&hl=zh-CN">Ling-Yu Duan</a>. 
                I will receive my PhD in 2023. In 2018, I obtained my B.Eng. degree in computer 
                In 2018, I obtained my master degree in <a href="https://english.pku.edu.cn/">Peking University</a>. 
                And in 2015, I obtained my B.Eng. degree in <a href="https://www.dlut.edu.cn/">Dalian University of Technology</a>.
              </p>
              <p> My current research focuses on computer vision, especially person re-identification, domain adaptation, and domain generalization.
              </p>
              <p style="text-align:center">
                <a href="mailto:yanbai@pku.edu.cn">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=zh-CN&user=hR0hxdgAAAAJ">Google Scholar</a> &nbsp/&nbsp
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="image/baiyan.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="image/baiyan.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>MPEG Standard</heading>
	    <p>
            I participate in the <a href="https://mpeg.chiariglione.org/">MPEG</a> international standard, ISO/IEC15938-13 <a href="https://mpeg.chiariglione.org/standards/mpeg-7/compact-descriptors-video-analysis">CDVA</a>. CDVA aims to standardize the compact descriptors for video analysis. Three technologies have been accepted.
            </p>
            <p>
              we propose a NIP feature based on nested invariance pooling, which is invariant on translation, scale and rotation. On the CDVA video dataset (1000 hours), the proposed method achieves 10% mAP improvement compared with the benchmark. The proposed 3 core technologies have been accepted by the CDVA standard.
            </p>
	    <p>
        <strong>Yan Bai</strong>, Yihang Lou, et al, Response to CDVA CE4: NIP Network Compression. Geneva 2017.1, m39853.
            </p>
            <p>
              <strong>Yan Bai</strong>, Yihang Lou, et al, Response to CDVA CE5: Binarization for NIP descriptor, Hobart 2017.4, m40387.
            </p>
          <p>
            Yihang Lou, <strong>Yan Bai</strong> et al, Improved retrieval and matching with CNN feature for CDVA, Chengdu 2016.10, w39219.
          </p>
          <p>
            <strong>Yan Bai</strong>, FengGao, et al, Suggestions on deep learning based technologies for CDVA. Chengdu 2016.10,w39220.
          </p>
          <p>
            <strong>Yan Bai</strong>, Yihang Lou, et al, Response to CDVA CE6: NIP Network Compression. Hobart 2017.4, m40386.
          </p>
          <p>
            Ziqian Chen, <strong>Yan Bai</strong>, et al, Study for the incremental representation for neural networks, Macau, 2018.10, m44050.
          </p>
          <p>
            Ziqian Chen, <strong>Yan Bai</strong>, et al, Response to Evidence on Neural Network Compression on CDVA, Macau, 2018.10, m44057.
          </p>
          <p>
            Yihang Lou, <strong>Yan Bai</strong>, et al, Response to CDVA CE4: Combination of NIP and CDVS Descriptors, Geneva 2017.1, m39852.
          </p>
          <p>
            Yihang Lou, <strong>Yan Bai</strong>, et al, Response to CE4: Supplement for NIP descriptor. Geneva 2017.1, m40161.
          </p>

          </td>
        </tr>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications & Preprints</heading>
              <p>
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="idm_plus_plus_stop()" onmouseover="idm_plus_plus_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='image/Dual-Tuning.png' width="160">
              </div>
              <script type="text/javascript">
                function idm_plus_plus_start() {
                  document.getElementById('idm_image').style.opacity = "1";
                }

                function idm_stop() {
                  document.getElementById('idm_image').style.opacity = "0";
                }
                idm_plus_plus_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2108.02959">
                <papertitle>Dual-Tuning: Joint Prototype Transfer and Structure Regularization for Compatible Feature Learning</papertitle>
              </a>
              <br>
              <strong>Yan Bai</strong>,
              Jile Jiao, Shengsen Wu, Yihang Lou, Jun Liu, Xuetao Feng, Ling-Yu Duan
              <br>
              <em>TMM, 2022
              <br>
              <p></p>
              <p>For the retrieval task, once the model is updated, the entire database features need to be re-extracted. Therefore, a feature compatibility learning strategy is designed to enable the learned new features to be directly compared with the old features.
                In this work, a prototype-based compatible loss is proposed, which uses prototypes to bridge and align the new and old embedding features in a global way. 
              </p>
            </td>
          </tr> 

          <tr onmouseout="dsu_stop()" onmouseover="dsu_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='image/VERI-Wild.png' width="160">
              </div>
              <script type="text/javascript">
                function dsu_start() {
                  document.getElementById('dsu_image').style.opacity = "1";
                }

                function dsu_stop() {
                  document.getElementById('dsu_image').style.opacity = "0";
                }
                idm_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9495181/">
                <papertitle>Disentangled Feature Learning Network and a Comprehensive Benchmark for Vehicle Re-identification</papertitle>
              </a>
              <br>
              <strong>Yan Bai</strong>, Jun Liu, Yihang Lou, Ce Wang, Ling-Yu Duan
              <br>
              <em>TPAMI</em>, 2021
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9495181/">paper</a>
              /
              <a href="https://github.com/PKU-IMRE/VERI-Wild">dataset</a>
              <p></p>
              <p>For vehicle/person ReID, we design a disentangled network to obtain the view-specific feature and view- invariant feature. An odd-one-out scheme is designed based on adversarial learning.
                An adaptive matching strategy is designed to adaptively exploit these two types of features. We create a large benchmark, VERI-Wild 2.0.
              </p>
            </td>
          </tr> 
          
          <tr onmouseout="digcl_stop()" onmouseover="digcl_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='image/Person30K.png' width="160">
              </div>
              <script type="text/javascript">
                function idm_start() {
                  document.getElementById('digcl_image').style.opacity = "1";
                }

                function idm_stop() {
                  document.getElementById('digcl_image').style.opacity = "0";
                }
                idm_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://openaccess.thecvf.com/content/CVPR2021/html/Bai_Person30K_A_Dual-Meta_Generalization_Network_for_Person_Re-Identification_CVPR_2021_paper.html">
                <papertitle>Person30k: A dual-meta generalization network for person re-identification</papertitle>
              </a>
              <br>
              <strong>Yan Bai</strong>, Jile Jiao, Wang Ce, Jun Liu, Yihang Lou, Xuetao Feng, Ling-Yu Duan
              <br>
							<em>CVPR</em>, 2021
              <br>
              <p></p>
              <p>A model will be deployed in various scenarios, which needs the model to have a strong generalization ability. We exploit the meta-learning scheme and design a “learning then generalization evaluation” training procedure.
                Besides, a discrimination loss is also incorporated for enhancing model discrimination.
              </p>
            </td>
          </tr> 

          <tr onmouseout="idm_stop()" onmouseover="idm_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='image/DA.png' width="160">
              </div>
              <script type="text/javascript">
                function idm_start() {
                  document.getElementById('idm_image').style.opacity = "1";
                }

                function idm_stop() {
                  document.getElementById('idm_image').style.opacity = "0";
                }
                idm_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9478234/">
                <papertitle>Hierarchical connectivity-centered clustering for unsupervised domain adaptation on person re-identification</papertitle>
              </a>
              <br>
              <strong>Yan Bai</strong>, Ce Wang, Yihang Lou, Jun Liu, Ling-Yu Duan
              <br>
							<em>TIP</em>, 2021
              <br>
              <p></p>
              <p>For unsupervised domain adaptation, a graph-based hierarchical clustering method is proposed to capture the complex cluster structure. Similar samples are first gathered, and then samples with intra-person variance are associated.
                A relation feature is designed to describe the unlabeled samples using source labels as references enhancing the feature robustness against intra-person variations.</p>
            </td>
          </tr> 
          <tr onmouseout="dualrefinement_stop()" onmouseover="dualrefinement_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='image/TIP_dual.PNG' width="160">
              </div>
              <script type="text/javascript">
                function dualrefinement_start() {
                  document.getElementById('dualrefinement_image').style.opacity = "1";
                }

                function dualrefinement_stop() {
                  document.getElementById('dualrefinement_image').style.opacity = "0";
                }
                dualrefinement_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://github.com/SikaStar/Dual-Refinement">
                <papertitle>Dual-Refinement: Joint Label and Feature Refinement for Unsupervised Domain Adaptive Person Re-Identification</papertitle>
              </a>
              <br>
              Yongxing Dai, Jun Liu, <strong>Yan Bai</strong>, Zekun Tong, Ling-Yu Duan
              <br>
							<em>IEEE Transactions on Image Processing (TIP)</em>, 2021 &nbsp
              <br>
              <a href="https://ieeexplore.ieee.org/document/9513260">paper</a>
							/
              <a href="https://arxiv.org/abs/2012.13689">arXiv</a>
							/
              <a href="https://github.com/SikaStar/Dual-Refinement">code</a>
              <p></p>
              <p>Dual-Refinement can jointly refine pseudo labels at the off-line clustering phase and features at the on-line training phase, to alternatively boost the label purity and feature discriminability in the target domain for
                more reliable re-ID.</p>
            </td>
          </tr> 


          <tr onmouseout="ijcai_stop()" onmouseover="ijcai_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='image/ijcai.PNG' width="160">
              </div>
              <script type="text/javascript">
                function ijcai_start() {
                  document.getElementById('ijcai_image').style.opacity = "1";
                }

                function ijcai_stop() {
                  document.getElementById('ijcai_image').style.opacity = "0";
                }
                ijcai_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.ijcai.org/proceedings/2020/0066.pdf">
                <papertitle>Disentangled Feature Learning Network for Vehicle Re-Identification</papertitle>
              </a>
              <br>
              <strong>Yan Bai</strong>, Yihang Lou, Yongxing Dai, Jun Liu, Ziqian Chen, Ling-Yu Duan
              <br>
							<em>IJCAI</em>, 2020 &nbsp
              <br>
              <a href="https://www.ijcai.org/proceedings/2020/0066.pdf">paper</a>
              <p></p>
              <p>We propose a Disentangled Feature Learning Network (DFLNet) to learn orientation specific and common features 
                concurrently. Moreover, to effectively use these two types of features for ReID, we further design a feature metric 
                alignment scheme to ensure the consistency of the metric scales.</p>
            </td>
          </tr> 


        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Honors</heading>
              <p>
                National Scholarship &nbsp &nbsp 2020</a>
              </p>
              <p>
                National Scholarship&nbsp &nbsp 2021</a>
              </p>
              <p>
                Outstanding Graduate of Beijing &nbsp &nbsp 2018</a>
              </p>
              <p>
                Outstanding Graduate of Liaoning Province &nbsp &nbsp 2015</a>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <br>
                <a href="https://jonbarron.info/">Website Template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
